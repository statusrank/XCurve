{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5790cd-1633-4532-80dd-91f3f8ff23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "from torch.optim import SGD # optimier (or one can use any optimizer supported by PyTorch)\n",
    "from XCurve.AUROC.losses import SquareAUCLoss # loss of AUROC\n",
    "from XCurve.AUROC.dataloaders import get_datasets # dataset of Xcurve\n",
    "from XCurve.AUROC.dataloaders import get_data_loaders # dataloader of Xcurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d247e4b-471c-469e-91ee-5f6777c95e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model or you can adopt any DNN models by Pytorch\n",
    "from XCurve.AUROC.models import generate_net\n",
    "\n",
    "# set params to create model\n",
    "args = edict({\n",
    "    \"model_type\": \"resnet18\", # (support resnet18,resnet20, densenet121 and mlp)\n",
    "    \"num_classes\": 2, # number of class\n",
    "    \"pretrained\": None # if the model is pretrained\n",
    "})\n",
    "model = generate_net(args).cuda() # generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35f3e17-9cee-43a2-8c3e-508c7908d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "optimizer = SGD(model.parameters(), lr=0.01) # create optimizer\n",
    "\n",
    "criterion = SquareAUCLoss(\n",
    "    num_classes=num_classes, # number of classes\n",
    "    gamma=1.0, # safe margin\n",
    "    transform=\"ovo\" # the manner of computing the multi-classes AUROC Metric ('ovo' or 'ova').\n",
    ") # create loss criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c344b2-67d0-4afb-aff1-e284c13be217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feng\\Xcurve\\XCurve\\example\\data\\XCurve\\AUROC\\dataloaders\\sampler.py:75: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(neg_samples, ignore_index=False)\n"
     ]
    }
   ],
   "source": [
    "# create Dataset (train_set, val_set, test_set) and dataloader (trainloader)\n",
    "# You can construct your own dataset/dataloader \n",
    "# but must ensure that there at least one sample for every class in each mini-batch \n",
    "# to calculate the AUROC loss. Or, you can do this:\n",
    "\n",
    "# set dataset params, see our doc. for more details.\n",
    "dataset_args = edict({\n",
    "    \"data_dir\": \"cifar-10-long-tail/\", # relative path of dataset\n",
    "    \"input_size\": [32, 32],\n",
    "    \"norm_params\": {\n",
    "        \"mean\": [123.675, 116.280, 103.530],\n",
    "        \"std\": [58.395, 57.120, 57.375]\n",
    "        },\n",
    "    \"use_lmdb\": True,\n",
    "    \"resampler_type\": \"None\",\n",
    "    \"sampler\": { # only used for binary classification\n",
    "        \"rpos\": 1,\n",
    "        \"rneg\": 10\n",
    "        },\n",
    "    \"npy_style\": True,\n",
    "    \"aug\": True, \n",
    "    \"class2id\": { # positive (minority) class idx\n",
    "        \"1\": 1, \"0\":0, \"2\":0, \"3\":0, \"4\":0, \"5\":0,\n",
    "        \"6\":0, \"7\":0, \"8\":0, \"9\":0\n",
    "    }\n",
    "})\n",
    "\n",
    "train_set, val_set, test_set = get_datasets(dataset_args) # load dataset\n",
    "trainloader, valloader, testloader = get_data_loaders(\n",
    "    train_set,\n",
    "    val_set,\n",
    "    test_set,\n",
    "    train_batch_size=32,\n",
    "    test_batch_size =64\n",
    ") # load dataset\n",
    "# Note that, in the get_datasets(), we conduct stratified sampling for train_set  \n",
    "# using the StratifiedSampler at from XCurve.AUROC.dataloaders import StratifiedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2bf840a-1253-4583-aec6-09d06742dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.15990693867206573\n",
      "loss: 0.2334757000207901\n",
      "loss: 0.30239760875701904\n",
      "loss: 0.1381421536207199\n",
      "loss: 0.13158641755580902\n",
      "loss: 0.38331863284111023\n",
      "loss: 0.08875473588705063\n",
      "loss: 0.20242173969745636\n",
      "loss: 0.32185712456703186\n",
      "loss: 0.15229110419750214\n",
      "loss: 0.11186783015727997\n",
      "loss: 0.11620910465717316\n"
     ]
    }
   ],
   "source": [
    "# forward of model for one epoch\n",
    "for index, (x, target) in enumerate(trainloader):\n",
    "    x, target  = x.cuda(), target.cuda()\n",
    "    # target.shape => [batch_size, ]\n",
    "    # Note that we ask for the prediction of the model among [0,1] \n",
    "    # for any binary (i.e., sigmoid) or multi-class (i.e., softmax) AUROC optimization.\n",
    "    \n",
    "    # forward\n",
    "    pred = torch.sigmoid(model(x)) # [batch_size, num_classess] when num_classes > 2, o.w. output [batch_size, ] \n",
    "    loss = criterion(pred, target)\n",
    "    if index % 30 == 0:\n",
    "        print(\"loss:\", loss.item())\n",
    "    \n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
