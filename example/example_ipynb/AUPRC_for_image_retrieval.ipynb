{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUPRC Loss for Image Retrieval\n",
    "\n",
    "This code base supports datasets, metrics and AUPRC loss for image retrieval.\n",
    "\n",
    "### Datasets\n",
    "\n",
    "The following class is a wrapper of image retrieval datasets:\n",
    "> CLASS XCurve.AUPRC.RetrievalDataset(data_dir, list_dir, subset, input_size, batchsize, num_sample_per_id, normal_mean=[0.485, 0.456, 0.406], normal_std=[0.229, 0.224, 0.225], split='train')  [\\[SOURCE\\]](https://github.com/statusrank/XCurve/blob/master/XCurve/AUPRC/datasets/dataset.py)\n",
    "\n",
    "#### Parameters:\n",
    "- data_dir (str): Path to the data.\n",
    "- list_dir (str): Path to the subset lists.\n",
    "- subset (str): Subset used for training, validation or testing.\n",
    "- input_size (int): Input image size.\n",
    "- batchsize (int): Number of samples per iteration. Must be consistent with the batch size of dataloader.\n",
    "- num_sample_per_id (int): Number of samples for each id.\n",
    "- normal_mean (list[int], optinal): Mean for model input normalization.\n",
    "- normal_std (list[int], optinal): Standard deviation for model input normalization.\n",
    "- split (str, options: ['train', 'val', 'test']): Data split.\n",
    "\n",
    "Three benchmark datasets are provided: iNaturalist, Stanford Online Products (SOP), and PKU VehicleID (VehID). The default configures are listed as dictionaries in `XCurve.AUPRC.DefaultInatDatasetCfg`, `XCurve.AUPRC.DefaultSOPDatasetCfg`, and `XCurve.AUPRC.DefaultVehIDDatasetCfg`, respectively. \n",
    "\n",
    "#### Functions:\n",
    "- RetrievalDataset.\\_\\_getitem\\_\\_(idx) -> tuple(torch.Tensor, torch.Tensor): Load an image and the corresponding labels.\n",
    "- RetrievalDataset.get_cnt_per_id() -> list\\[int\\]: Load a list describing the number of samples for each id.\n",
    "- RetrievalDataset.reset() -> None: Shuffle the data. It should be called after an epoch.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subset': None, 'dataset_train': 'train', 'dataset_val': 'val', 'dataset_test': 'test', 'data_dir': './data/iNaturalist/images', 'list_dir': './data/iNaturalist/split_list', 'num_sample_per_id': 4, 'inst_blc': True, 'input_size': 256, 'batchsize': 56, 'normal_mean': [0.485, 0.456, 0.406], 'normal_std': [0.229, 0.224, 0.225]}\n",
      "\n",
      "shuffling data...\n",
      "train set has 278656 samples per epoch\n",
      "[26, 30, 24, 19, 22, 13, 16, 15, 23, 19]\n",
      "torch.Size([56, 3, 256, 256]) torch.Size([56, 1])\n",
      "\n",
      "shuffling data...\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from XCurve.AUPRC import RetrievalDataset, DefaultInatDatasetCfg\n",
    "\n",
    "args = DefaultInatDatasetCfg\n",
    "print(args)\n",
    "dataset = RetrievalDataset(**args, split='train')\n",
    "dataloader = DataLoader(dataset, batch_size=args.batchsize, num_workers=4)\n",
    "print(dataloader.dataset.get_cnt_per_id()[:10])\n",
    "for i, (img, lbl) in enumerate(dataloader):\n",
    "    print(img.shape, lbl.shape)\n",
    "    ## do something here\n",
    "    break\n",
    "dataloader.dataset.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUPRC Loss\n",
    "\n",
    "The following functions build the class to compute the List-stable AUPRC loss:\n",
    "> XCurve.AUPRC.ListStableAUPRC(tau1=0.1, tau2=0.001, beta=0.001, prior_mul=0.1,\n",
    "num_sample_per_id=4, var_reg_weight_pos=5, var_reg_weight_neg=1) -> SOPRC [\\[SOURCE\\]](https://github.com/statusrank/XCurve/blob/master/XCurve/AUPRC/losses/__init__.py)\n",
    "\n",
    "#### Parameters:\n",
    "- tau1 (float): Control the surrogate loss of pos-neg pairs. See \\tau_1 in Eq.(7).\n",
    "- tau2 (float): Control the surrogate loss of pos-pos pairs. See \\tau_2 in Eq.(7).\n",
    "- beta (float): Control the exponential moving average. See \\beta in Eq.(10).\n",
    "- prior_mul (float): Imbalance ratio of the id with most positive examples.\n",
    "- num_sample_per_id (int): Number of examples for each id.\n",
    "- var_reg_weight_pos (float): Weight of the variance regular term w.r.t. positive examples.\n",
    "- var_reg_weight_neg (float): Weight of the variance regular term w.r.t. negative examples.\n",
    "\n",
    "The default configures are listed as dictionaries in `XCurve.AUPRC.DefaultLossCfg`.\n",
    "\n",
    "The following class supports the computation of List-stable AUPRC loss, where the parameters are the same as above:\n",
    "> CLASS SOPRC (num_sample_per_id, temp, beta, prior_mul=0.1, **kwargs) [\\[SOURCE\\]](https://github.com/statusrank/XCurve/blob/master/XCurve/AUPRC/losses/soprc.py)\n",
    "\n",
    "#### Functions:\n",
    "- SOPRC.forward(feats, targets) -> torch.Tensor: Compute loss.\n",
    "- SOPRC.update_cnt_per_id(cnt_per_id) -> None: Update a list describing the number of samples for each id. It must be called before running.\n",
    "\n",
    "#### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shuffling data...\n",
      "train set has 280056 samples per epoch\n",
      "1.0337904691696167\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from XCurve.AUPRC import (ListStableAUPRC, DefaultLossCfg, \\\n",
    "    RetrievalDataset, DefaultInatDatasetCfg)\n",
    "\n",
    "dataset = RetrievalDataset(**DefaultInatDatasetCfg, split='train')\n",
    "criterion = ListStableAUPRC(**DefaultLossCfg)\n",
    "criterion.update_cnt_per_id(dataset.get_cnt_per_id())\n",
    "feats = F.normalize(torch.randn((16, 128)).cuda(), dim=1, p=2)\n",
    "targets = torch.tensor([5,5,5,5,3,3,3,3,1,1,1,1,9,9,9,9]).cuda()\n",
    "loss = criterion(feats, targets)\n",
    "print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c7b29a3529c140420126446c3d126c7a36d0833188f5baf93b843fa26825432"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pytorch1.8': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
