{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63378f2",
   "metadata": {},
   "source": [
    "## How to conduct AUTKC optimization?\n",
    "\n",
    "This example illustrates how to perform AUTKC optimization by the XCurve libraray.\n",
    "\n",
    "### Import optimizer, loss function, dataset, and dataloader.\n",
    "\n",
    "First, we get dataloader for training and validation by the `get_data_loader` function, whose essential parameters are explained below:\n",
    "- `dataset_dir`: This parameter specifies the directory of the dataset. We have implement `cifar-10`, `cifar-100`, `tiny-imagenet-200`, and `place-365`;\n",
    "- `batch_size`: This parameter specifies the size of each batch for the dataloader;\n",
    "- `workers`: This parameter specifies the number of workers for the dataloader;\n",
    "- `train_ratio`: This parameter specifies the ratio of samples for training, and the other samples will be used for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143c6e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from XCurve.AUTKC.dataloaders import get_data_loader\n",
    "\n",
    "dataset_root, dataset = 'D:/dataset', 'cifar-100'\n",
    "dataset_dir = os.path.join(dataset_root, dataset)\n",
    "train_loader, val_loader, _, num_class = get_data_loader(dataset_dir, batch_size=128, workers=4, train_ratio=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489ad62",
   "metadata": {},
   "source": [
    "Then, we build the model, the loss function, and the optimizer. By default, we use the `resnet18` provided by Pytorch. The `StandardAUTKCLoss` function return the AUTKC loss, whose essential parameters are explained below:\n",
    "- `surrogate`: This parameter specifies the surrogate loss, whose options include `Sq`, `Exp`, `Logit`, and `Hinge`;\n",
    "- `K`: This parameter specifies the hyperparameter `K` for the AUTKC loss;\n",
    "- `epoch_to_paced`: This parameter specifies the number of warm-up epoch for training. By default, we use the CE loss as the warm-up loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528d6308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45504\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\45504\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from XCurve.AUTKC.losses.AUTKCLoss import StandardAUTKCLoss\n",
    "import torch.optim as optim\n",
    "\n",
    "model = models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_class)  \n",
    "model = model.cuda()\n",
    "\n",
    "surrogate, K, epoch_to_paced = 'Sq', 5, 3\n",
    "criterion = StandardAUTKCLoss(surrogate, K, epoch_to_paced).cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f767d8",
   "metadata": {},
   "source": [
    "Finally, we train the model for 10 epochs. To this end, we first specify the `k_list` for evaluation. In each epoch, the codes follow a stanard Pytorch trainging pipeline. And we use the `evaluate` function to get the Top-k accuracy and the AUTKC performance under the given k-list. \n",
    "\n",
    "For a more detailed training process, please refer to `example/data/autkc.py` and run `python autkc.py --loss autkc --surrogate Exp --resume checkpoints/*** `."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5b42f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tAUTKC@3 33.80 (33.80)  AUTKC@5 40.83 (40.83)\tAcc@3 40.28 (40.28)  Acc@5 54.17 (54.17)\n",
      "1\tAUTKC@3 43.52 (38.66)  AUTKC@5 50.00 (45.42)\tAcc@3 51.39 (45.83)  Acc@5 61.11 (57.64)\n",
      "2\tAUTKC@3 40.28 (39.20)  AUTKC@5 45.83 (45.56)\tAcc@3 47.22 (46.30)  Acc@5 55.56 (56.94)\n",
      "3\tAUTKC@3 57.41 (43.75)  AUTKC@5 63.61 (50.07)\tAcc@3 68.06 (51.74)  Acc@5 75.00 (61.46)\n",
      "4\tAUTKC@3 57.87 (46.57)  AUTKC@5 62.22 (52.50)\tAcc@3 63.89 (54.17)  Acc@5 69.44 (63.06)\n",
      "5\tAUTKC@3 56.02 (48.15)  AUTKC@5 61.94 (54.07)\tAcc@3 63.89 (55.79)  Acc@5 72.22 (64.58)\n",
      "6\tAUTKC@3 53.24 (48.88)  AUTKC@5 59.72 (54.88)\tAcc@3 63.89 (56.94)  Acc@5 69.44 (65.28)\n",
      "7\tAUTKC@3 62.50 (50.58)  AUTKC@5 67.22 (56.42)\tAcc@3 70.83 (58.68)  Acc@5 75.00 (66.49)\n",
      "8\tAUTKC@3 62.96 (51.95)  AUTKC@5 66.39 (57.53)\tAcc@3 69.44 (59.88)  Acc@5 72.22 (67.13)\n",
      "9\tAUTKC@3 67.13 (53.47)  AUTKC@5 72.50 (59.03)\tAcc@3 75.00 (61.39)  Acc@5 81.94 (68.61)\n"
     ]
    }
   ],
   "source": [
    "from XCurve.AUTKC.metrics import evaluate\n",
    "from XCurve.AUTKC.utils.common_utils import AverageMeter\n",
    "\n",
    "k_list = [3, 5]\n",
    "topks = [AverageMeter('Acc@%d' % k, ':6.2f') for k in k_list]\n",
    "autkcs = [AverageMeter('AUTKC@%d' % k, ':6.2f') for k in k_list]\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        targets = targets.squeeze().cuda(non_blocking =True)\n",
    "        inputs = inputs.float().cuda(non_blocking =True)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, targets, epoch) if hasattr(criterion, 'epoch_to_paced') else criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    accs, autkc= evaluate(outputs.data, targets, k_list)\n",
    "    for _ in range(len(k_list)):\n",
    "        topks[_].update(accs[_], inputs.size(0))\n",
    "        autkcs[_].update(autkc[_], inputs.size(0))\n",
    "\n",
    "    autkc_str = '  '.join(['AUTKC@{} {autkcs.val:.2f} ({autkcs.avg:.2f})'.format(k_list[_], autkcs=autkcs[_]) for _ in range(len(k_list))])\n",
    "    topks_str = '  '.join(['Acc@{} {topk.val:.2f} ({topk.avg:.2f})'.format(k_list[_], topk=topks[_]) for _ in range(len(k_list))])\n",
    "    print(epoch, autkc_str, topks_str, sep='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
